# .github/workflows/build-package.yaml
#
# 功能：建立、驗證並加密一個「增量」或「全量」更新包。
#       此版本已改用 Python 腳本 (create_package.py) 進行打包，並增加了自動化驗證與 GPG 加密流程。
#       最終產物為一個 .tar.gz.gpg 加密檔案，傳送至遠端主機。
#
# 觸發：
#   1. Pull Request 關閉並合併至 main 分支時。
#   2. 手動觸發 (workflow_dispatch)，支援 dry_run / debug / 指定版本區間。
#
# 版本推算規則：
#   ─ 手動 new_tag 是 tag  → 舊版 = new_tag 的上一個 tag
#   ─ 手動 new_tag 是 hash → 舊版 = new_tag 之前最近的 tag
#   ─ 事件自動（或 new_tag 空） → 新版 = HEAD，舊版 = 最近 tag
#   ─ 手動同時給 previous_tag → 直接用指定區間
#
# 部署設定：
#   • Secrets (必須設定):
#     - REMOTE_SSH_PASSWORD: 用於部署的 SSH 密碼。
#     - GPG_PASSPHRASE:    用於 GPG 對稱加密的私鑰。
#   • 主機與路徑: IP、使用者、目錄等設定已直接在此檔案的 "Define Environment Variables" 步驟中指定。
#
name: Build, Verify, Encrypt & Deploy Package

on:
  pull_request:
    types: [closed]
    branches: [main]
  workflow_dispatch:
    inputs:
      encrypt_package:
        description: "true -> 對產出的包進行 GPG 加密 (預設)"
        type: boolean
        default: true
      full_package:
        description: "true -> 建立包含所有檔案的『全量包』"
        type: boolean
        default: false
      dry_run:
        description: "true -> 只建構和驗證，不執行遠端部署"
        type: boolean
        default: false
      override_host:
        description: "臨時覆寫遠端主機 IP (留空則使用預設值)"
        type: string
        default: ""
      new_tag:
        description: "新版本 (tag/hash, 留空為 HEAD)"
        type: string
        default: ""
      previous_tag:
        description: "舊版本 (tag/hash, 留空則自動推算)"
        type: string
        default: ""

jobs:
  # This single job handles the entire process from build to deploy
  # to simplify logic and avoid cross-job variable passing issues.
  build_verify_encrypt_deploy:
    if: github.event.pull_request == null || github.event.pull_request.merged == true
    runs-on: ubuntu-22.04

    steps:
      - name: Install prerequisite tools
        run: |
          sudo apt-get update && sudo apt-get install -y \
            sshpass \
            tree \
            gnupg

      - name: Checkout repository (full history)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Upgrade pip
        run: python -m pip install --upgrade pip

      - name: Install script dependencies
        run: pip install pathspec

      - name: Define Environment Variables
        id: envset
        run: |
          # Safely access inputs, providing defaults for non-dispatch events.
          # This prevents errors when the workflow is triggered by non-dispatch events.
          IS_FULL_PACKAGE="${{ (github.event_name == 'workflow_dispatch' && github.event.inputs.full_package) || 'false' }}"
          IS_DRY_RUN="${{ (github.event_name == 'workflow_dispatch' && github.event.inputs.dry_run) || 'false' }}"
          OVERRIDE_HOST="${{ (github.event_name == 'workflow_dispatch' && github.event.inputs.override_host) || '' }}"
          NEW_TAG_INPUT="${{ (github.event_name == 'workflow_dispatch' && github.event.inputs.new_tag) || '' }}"

          # Determine remote host IP
          if [ -n "$OVERRIDE_HOST" ]; then
            REMOTE_HOST="$OVERRIDE_HOST"
          else
            REMOTE_HOST="itgsystem3.asuscomm.com"
          fi

          # Hardcoded user and directory for the target server
          REMOTE_USER="user"
          REMOTE_DIR="/home/user/tmp/users/jason"

          # Write to GITHUB_ENV for use in subsequent steps of this job.
          # We no longer need GITHUB_OUTPUT as we are now in a single job.
          echo "IS_FULL_PACKAGE=$IS_FULL_PACKAGE" >> $GITHUB_ENV
          echo "DRY_RUN=$IS_DRY_RUN" >> $GITHUB_ENV
          echo "NEW_TAG_INPUT=$NEW_TAG_INPUT" >> $GITHUB_ENV
          echo "REMOTE_HOST=$REMOTE_HOST" >> $GITHUB_ENV
          echo "REMOTE_USER=$REMOTE_USER" >> $GITHUB_ENV
          echo "REMOTE_DIR=$REMOTE_DIR" >> $GITHUB_ENV

      - name: Determine version range
        id: ver
        if: env.IS_FULL_PACKAGE != 'true'
        run: |
          set -e
          NEW_TAG="${{ (github.event_name == 'workflow_dispatch' && github.event.inputs.new_tag) || 'HEAD' }}"
          PREVIOUS_TAG="${{ (github.event_name == 'workflow_dispatch' && github.event.inputs.previous_tag) || '' }}"

          if [ -n "$PREVIOUS_TAG" ]; then
            OLD_TAG="$PREVIOUS_TAG"
          else
            if git describe --exact-match --tags "$NEW_TAG" &>/dev/null; then
              OLD_TAG=$(git describe --tags --abbrev=0 "${NEW_TAG}^" 2>/dev/null)
            else
              OLD_TAG=$(git describe --tags --abbrev=0 "$NEW_TAG" 2>/dev/null)
            fi
          fi

          if [ -z "$OLD_TAG" ]; then
            echo "No previous tag found. Using the first commit as the old version."
            OLD_TAG=$(git rev-list --max-parents=0 HEAD)
          fi

          NEW_TAG_SHA=$(git rev-parse "$NEW_TAG")

          echo "old_tag=$OLD_TAG" >> "$GITHUB_OUTPUT"
          echo "new_tag_sha=$NEW_TAG_SHA" >> "$GITHUB_OUTPUT"
          echo "Packaging Range: $OLD_TAG -> $NEW_TAG"

      - name: Build Package
        id: pkg
        run: |
          if ! SCRIPT_PATH=$(find . -type f -name 'create_package.py' -print -quit); then
            echo "Error: Packaging script 'create_package.py' not found." >&2
            exit 1
          fi

          if [[ "$IS_FULL_PACKAGE" == "true" ]]; then
            echo "--- Building FULL package ---"
            NEW_VERSION="${{ (github.event_name == 'workflow_dispatch' && github.event.inputs.new_tag) || 'HEAD' }}"
            python3 "$SCRIPT_PATH" "ignored" "$NEW_VERSION" --full
          else
            echo "--- Building INCREMENTAL package ---"
            python3 "$SCRIPT_PATH" "${{ steps.ver.outputs.old_tag }}" "${{ (github.event_name == 'workflow_dispatch' && github.event.inputs.new_tag) || 'HEAD' }}"
          fi

          PKG_NAME=$(ls -t ITG_*.tar.gz | head -n 1)
          if [ -z "$PKG_NAME" ]; then
            echo "Error: No package file was created." >&2
            exit 1
          fi

          echo "pkg_name=$PKG_NAME" >> "$GITHUB_OUTPUT"
          echo "Generated package: $PKG_NAME"
          ls -lh "$PKG_NAME"

      - name: Verify requirements.txt Completeness (pip check)
        run: |
          echo "Verifying that each requirements.txt is a complete dependency freeze..."

          # We check the original source code, not the extracted package content.
          # This check runs regardless of package type (incremental or full).
          MODULE_DIRS=$(find . -maxdepth 2 -name "requirements.txt" -exec dirname {} \; 2>/dev/null || true)

          if [ -n "$MODULE_DIRS" ]; then
            for MODULE_DIR in $MODULE_DIRS; do
              REQ_FILE="$MODULE_DIR/requirements.txt"
              # Trim leading './' for cleaner display name
              MODULE_NAME=$(echo "$MODULE_DIR" | sed 's|^\./||')
              
              echo "--- Checking module: $MODULE_NAME ---"
              
              # Create a temporary, isolated virtual environment for this check
              python3 -m venv "./venv-check-$MODULE_NAME"
              source "./venv-check-$MODULE_NAME/bin/activate"
              
              # Upgrade pip inside the venv
              pip install --upgrade pip > /dev/null
              
              # Install dependencies from the requirements file. Pip will fetch from PyPI.
              pip install -r "$REQ_FILE" > /dev/null
              
              # Now, check if the installed environment is consistent.
              # If requirements.txt was missing a sub-dependency, `pip check` will fail.
              echo "Running 'pip check' for module $MODULE_NAME..."
              pip check
              
              # Deactivate and clean up the temporary environment
              deactivate
              rm -rf "./venv-check-$MODULE_NAME"
              echo "--- Completeness check for $MODULE_NAME PASSED ---"
            done
          else
            echo "No requirements.txt files found, skipping completeness check."
          fi

      - name: Verify Package Integrity
        id: verify
        run: |
          PKG_NAME="${{ steps.pkg.outputs.pkg_name }}"
          mkdir -p ./verify_contents

          # Extract the package for verification
          tar --no-same-owner --no-same-permissions -xvf "$PKG_NAME" -C ./verify_contents

          # Smart Check: Use different verification strategies for incremental vs full packages
          # It finds all requirements.txt files within the extracted 'app' directory.
          MODULE_REQ_FILES=$(find ./verify_contents/app -maxdepth 2 -name "requirements.txt" 2>/dev/null || true)

          if [ -z "$MODULE_REQ_FILES" ]; then
            echo "No requirements.txt found in the package, skipping dependency verification."
          else
            echo "--- Verifying dependencies module by module ---"
            for REQ_FILE in $MODULE_REQ_FILES; do
              # Determine the module path relative to 'app'
              # e.g., './verify_contents/app/RestAPI/requirements.txt' -> 'RestAPI'
              APP_DIR=$(dirname "$REQ_FILE")
              MODULE_PATH=$(realpath --relative-to=./verify_contents/app "$APP_DIR")
              
              echo "--- Checking module: $MODULE_PATH ---"

              # The corresponding wheel directory for this module
              WHEELS_DIR="./verify_contents/wheels/$MODULE_PATH"

              # If there are no wheels for this module (e.g., in an incremental package
              # where this module's dependencies didn't change), we skip the check.
              if [ ! -d "$WHEELS_DIR" ] || [ -z "$(ls -A "$WHEELS_DIR")" ]; then
                echo "No new/updated wheels for module $MODULE_PATH, skipping installation check."
                continue
              fi

              # each service has its own venv.
              # 1. create a temporary, isolated virtual environment for this specific module.
              TEMP_VENV="./venv-check-$MODULE_PATH"
              python3 -m venv "$TEMP_VENV"
              source "$TEMP_VENV/bin/activate"

              # 2. try to install the requirements for THIS module, using ONLY its own wheels.
              # This will succeed even if the wheels only contain a subset of dependencies
              # (like in an incremental package), as pip will fetch the rest from PyPI.
              # The goal is to ensure the packaged wheels themselves are valid and not conflicting
              # within the scope of a single module's installation.
              echo "Attempting to install requirements from $REQ_FILE using wheels from $WHEELS_DIR..."
              pip install --no-cache-dir --find-links="$WHEELS_DIR" -r "$REQ_FILE"

              # 3. If the installation succeeds, it means the wheels for this module are valid.
              # We then clean up the environment.
              deactivate
              rm -rf "$TEMP_VENV"
              echo "--- Verification for module $MODULE_PATH PASSED ---"
            done
          fi
          echo "All package integrity checks PASSED."

      - name: Finalize and Encrypt Package
        # This step runs ONLY if encryption is enabled and not a dry-run
        if: inputs.encrypt_package == true && inputs.dry_run != true
        env:
          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}
          SSH_PASSWORD: ${{ secrets.REMOTE_SSH_PASSWORD }}
        run: |
          # Check if secrets are set
          if [ -z "$GPG_PASSPHRASE" ]; then echo "Error: GPG_PASSPHRASE secret is not set." >&2; exit 1; fi
          if [ -z "$SSH_PASSWORD" ]; then echo "Error: REMOTE_SSH_PASSWORD secret is not set." >&2; exit 1; fi

          CANDIDATE_PKG_NAME="${{ steps.pkg.outputs.pkg_name }}"

          # First, encrypt and upload the candidate package (e.g., ..._to_HEAD.tar.gz)
          echo "Encrypting candidate package '$CANDIDATE_PKG_NAME'..."
          CANDIDATE_GPG_NAME="${CANDIDATE_PKG_NAME}.gpg"
          gpg --batch --yes --symmetric --cipher-algo AES256 --passphrase "$GPG_PASSPHRASE" -o "$CANDIDATE_GPG_NAME" "$CANDIDATE_PKG_NAME"

          echo "Uploading candidate package to remote server..."
          sshpass -p "$SSH_PASSWORD" ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null "$REMOTE_USER@$REMOTE_HOST" "mkdir -p $REMOTE_DIR"
          sshpass -p "$SSH_PASSWORD" scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null "$CANDIDATE_GPG_NAME" "$REMOTE_USER@$REMOTE_HOST:$REMOTE_DIR/"

          # Now, create and upload the final package with commit hash if it was a HEAD build
          if [[ "${{ env.NEW_TAG_INPUT }}" == "" ]]; then
            COMMIT_SHA_SHORT=$(echo "${{ steps.ver.outputs.new_tag_sha || github.sha }}" | cut -c1-8)
            if [[ "$CANDIDATE_PKG_NAME" == ITG_Update_* ]]; then
              FINAL_PKG_NAME=$(echo "$CANDIDATE_PKG_NAME" | sed "s/_to_HEAD.tar.gz$/_to_${COMMIT_SHA_SHORT}.tar.gz/")
            else
              FINAL_PKG_NAME=$(echo "$CANDIDATE_PKG_NAME" | sed "s/_HEAD.tar.gz$/_${COMMIT_SHA_SHORT}.tar.gz/")
            fi
            
            # Encrypt the final package as well
            FINAL_GPG_NAME="${FINAL_PKG_NAME}.gpg"
            echo "Encrypting final package '$FINAL_PKG_NAME'..."
            gpg --batch --yes --symmetric --cipher-algo AES256 --passphrase "$GPG_PASSPHRASE" -o "$FINAL_GPG_NAME" "$CANDIDATE_PKG_NAME" # Source is still the original .tar.gz

            echo "Uploading final package to remote server..."
            sshpass -p "$SSH_PASSWORD" scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null "$FINAL_GPG_NAME" "$REMOTE_USER@$REMOTE_HOST:$REMOTE_DIR/"
          fi

          echo "Upload(s) complete."

      - name: Upload Unencrypted Package
        # This step runs ONLY if encryption is disabled and not a dry-run
        if: inputs.encrypt_package == false && inputs.dry_run != true
        env:
          SSH_PASSWORD: ${{ secrets.REMOTE_SSH_PASSWORD }}
        run: |
          if [ -z "$SSH_PASSWORD" ]; then echo "Error: REMOTE_SSH_PASSWORD secret is not set." >&2; exit 1; fi

          CANDIDATE_PKG_NAME="${{ steps.pkg.outputs.pkg_name }}"

          # First, upload the candidate package
          echo "Uploading candidate package '$CANDIDATE_PKG_NAME' to remote server..."
          sshpass -p "$SSH_PASSWORD" ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null "$REMOTE_USER@$REMOTE_HOST" "mkdir -p $REMOTE_DIR"
          sshpass -p "$SSH_PASSWORD" scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null "$CANDIDATE_PKG_NAME" "$REMOTE_USER@$REMOTE_HOST:$REMOTE_DIR/"

          # Now, copy and upload the final package with commit hash if it was a HEAD build
          if [[ "${{ env.NEW_TAG_INPUT }}" == "" ]]; then
            COMMIT_SHA_SHORT=$(echo "${{ steps.ver.outputs.new_tag_sha || github.sha }}" | cut -c1-8)
            if [[ "$CANDIDATE_PKG_NAME" == ITG_Update_* ]]; then
              FINAL_PKG_NAME=$(echo "$CANDIDATE_PKG_NAME" | sed "s/_to_HEAD.tar.gz$/_to_${COMMIT_SHA_SHORT}.tar.gz/")
            else
              FINAL_PKG_NAME=$(echo "$CANDIDATE_PKG_NAME" | sed "s/_HEAD.tar.gz$/_${COMMIT_SHA_SHORT}.tar.gz/")
            fi
            
            # Copy the file to its new name
            cp "$CANDIDATE_PKG_NAME" "$FINAL_PKG_NAME"
            
            echo "Uploading final package '$FINAL_PKG_NAME' to remote server..."
            sshpass -p "$SSH_PASSWORD" scp -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null "$FINAL_PKG_NAME" "$REMOTE_USER@$REMOTE_HOST:$REMOTE_DIR/"
          fi

          echo "Upload(s) complete."

      - name: Store Final Package as Artifact
        # This step now focuses on finding and uploading ONLY the final, versioned package.
        id: find_final_pkg
        run: |
          # The goal is to find the package named with the commit hash, if it exists.
          # Otherwise, fall back to the package named with the tag or HEAD.

          FINAL_PKG_NAME=""
          # Check for a hash-named encrypted file first
          if ls ITG_*_to_????????.tar.gz.gpg >/dev/null 2>&1; then
            FINAL_PKG_NAME=$(ls ITG_*_to_????????.tar.gz.gpg)
          # Check for a hash-named unencrypted file
          elif ls ITG_*_to_????????.tar.gz >/dev/null 2>&1; then
            FINAL_PKG_NAME=$(ls ITG_*_to_????????.tar.gz)
          # Fallback to any remaining gpg file
          elif ls *.tar.gz.gpg >/dev/null 2>&1; then
            FINAL_PKG_NAME=$(ls -t *.tar.gz.gpg | head -n 1)
          # Fallback to any remaining tar.gz file
          elif ls *.tar.gz >/dev/null 2>&1; then
            FINAL_PKG_NAME=$(ls -t *.tar.gz | head -n 1)
          fi

          if [ -n "$FINAL_PKG_NAME" ]; then
            echo "Found final package for artifact upload: $FINAL_PKG_NAME"
            echo "pkg_name=$FINAL_PKG_NAME" >> "$GITHUB_OUTPUT"
          else
            echo "No final package found to upload as artifact."
          fi

      - uses: actions/upload-artifact@v4
        if: steps.find_final_pkg.outputs.pkg_name
        with:
          # Use the exact filename found in the previous step
          name: ${{ steps.find_final_pkg.outputs.pkg_name }}
          path: ${{ steps.find_final_pkg.outputs.pkg_name }}
          retention-days: 1
